## Site Reliability Engineering
<i><small>How google runs production systems</small></i>

<br/>

### Part I. Introduction

- CHAPTER 01. Introduction

<details>
<summary><b>CHAPTER 02. The Production Environment at Google, from the Viewpoint of an SRE</b></summary>
<br>

[🔗 link](./chapter02)

<br/>

**TL;DR**
- **하드웨어 구성**: 구글의 데이터센터는 동일한 하드웨어 유형을 사용하고 클러스터 운영 시스템인 Borg가 자원 할당을 관리함. 클러스터-데이터센터-캠퍼스 구조를 형성하며, "주피터" 네트워크로 연결됨.
- **시스템 소프트웨어 관리**: 대규모 하드웨어 문제를 소프트웨어로 관리하며, Borg가 자원 관리를 담당함. 스토리지 계층에는 Colossus(구글 파일 시스템 후속), Bigtable, Spanner 등이 사용됨.
- **네트워킹**: 오픈플로우(OpenFlow) 기반의 SDN을 사용해 스마트 라우팅 하드웨어 대신 단순한 스위치와 중앙 컨트롤러로 네트워크를 관리함. 글로벌 소프트웨어 로드 밸런서(GSLB)를 통해 다양한 수준에서 로드 밸런싱을 수행함.
- **잠금 서비스**: Chubby는 비동기 합의를 통해 일관성 있는 데이터 잠금과 관리 제공.
- **모니터링과 경고**: Borgmon을 사용해 지표를 수집하고 문제 발생 시 알림을 제공하여 시스템 상태와 자원 소비를 모니터링함.
- **소프트웨어 인프라**: Stubby를 통한 원격 프로시저 호출(RPC)로 통신하고, 프로토콜 버퍼(Protocol Buffers)로 데이터 전송.
- **개발 환경**: 코드 변경은 리뷰를 통해 검토하고 배포, 모든 소스 코드 수정은 리뷰 후 제출됨.

<br/>
</details>

### Part II. Principles

<details>
<summary><b>CHAPTER 03. Embracing RiskEmbracing Risk</b></summary>
<br>

[🔗 link](./chapter03)

<br/>

**TL;DR**
- **리스크 관리**: 신뢰성을 높이는 데 필요한 비용은 비례적으로 증가하지 않으며, 때로는 100배까지도 높아질 수 있음.
  - **비용 요소**: 여분의 컴퓨트 자원 비용, 기회 비용.
- **서비스 리스크 측정**: 단일 지표로는 서비스 리스크를 완전히 파악하기 어려움.
  - 구글은 시간 기준 가용성 대신 요청 성공률을 기준으로 가용성을 정의함.
- **서비스의 위험 수용도**: 제품 정의 및 목표에 따라 위험 수용도를 설정함.
  - **고려사항**: 장애 유형, 위험 대비 비용, 목표 가용성 수준, 비용 대비 추가 수익.
- **에러 예산 활용**: 소프트웨어 결함을 어느 정도 허용할지, 출시 빈도, 테스트 전략을 조정하여 유연성과 사용성의 균형을 맞춤.
  - 에러 예산을 통해 출시 리스크와 품질 관리를 균형 있게 조율.
- **카나리 테스트**: 새로운 코드 도입 시 일부 구간에서 테스트하는 방법으로, 기간과 규모 조정이 중요.

<br/>
</details>
<details>
<summary><b>CHAPTER 04. Service Level Objectives</b></summary>
<br>

[🔗 link](./chapter04)

<br/>

**TL;DR**
- **SLI**: **서비스 수준 지표**. 서비스의 가용성, 응답 속도, 오류율 등을 측정하는 정량적 지표.
- **SLO**: **서비스 수준 목표**. 특정 SLI의 목표 범위(예: 응답 시간 95% 이하).
- **SLA**: **서비스 수준 협약**. SLO를 달성하지 못할 경우 사용자와의 보상 계약.
- **지표 설정**: 모든 지표를 SLI로 설정할 필요는 없으며, 중요한 척도만 선택.
  - 지표 표준화는 효율성 향상에 기여.
- **목표 설정 가이드라인**:
  - 현재 성능 기준 사용 금지.
  - SLI 단순화.
  - 사용자 만족 수준을 초과하지 않음.
  - 적은 수의 SLO 설정.
  - 초기 목표는 점진적 개선 가능하도록 설정.
- **제어 루프**: SLI를 모니터링하고 SLO와 비교해 대응 필요 여부를 판단.
- **SLA 설정**: 보수적 SLO 설정과 사용자가 이해할 보상체계가 중요.

<br/>
</details>
<details>
<summary><b>CHAPTER 05. Eliminating Toil</b></summary>
<br>

[🔗 link](./chapter05)

<br/>

**TL;DR**

- **삽질(Toil)**: 반복적이고 자동화가 가능하지만 수작업으로 처리되는 비효율적 업무.
  - 수작업 필요, 반복적, 자동화 가능, 사후 대처 필요, 지속적 가치 없음, 서비스 성장에 따라 증가함.
  - **삽질을 줄이는 이유**: 구글 SRE는 삽질을 50% 이하로 유지하여 효율성을 높이고 서비스 확장성을 강화하려 함.
- **엔지니어링 업무**:
  - **소프트웨어 엔지니어링**: 코드 작성, 자동화 스크립트, 확장성 향상.
  - **시스템 엔지니어링**: 설정 조정, 문서화, 로드 밸런서 설치.
  - **삽질**: 반복적인 수작업.
  - **부하**: 직접적이지 않은 관리 업무.
- 삽질이 많아지면 **경력 침체, 의욕 저하, 성장 둔화, 신뢰 문제 발생**.
- **결론**: 창의적 업무에 집중하기 위해 모든 사람이 매주 삽질을 줄여야 함.

<br/>
</details>
<details>
<summary><b>CHAPTER 06. Monitoring Distributed Systems</b></summary>
<br>

[🔗 link](./chapter06)

<br/>

**TL;DR**

- **모니터링**
  - **모니터링 정의**: 시스템의 정량적 실시간 데이터를 모으고 처리하고 집계해서 보여주는 것
  - **화이트박스(white-box) 모니터링**: 로그나 자바 가상 머신 (Java Virtual Machine, JVM) 의 프로파일링 인터페이스 (profling interface) 같은 인터페이스 혹은 내부의 통계 지표를 제공하는 HTTP 핸들러 등을 이용해서 얻은 시스템의 내부 지표들을 토대로하는 모니터링
  - **블랙박스 (black-box) 모니터링**: 사용자가 보게 되는 확인 가능한 동작들을 외부에서 테스트하는 과정
  - **대시보드 (dash board)**: 서비스의 핵심 지표에 대한 요약된 뷰를 보여주는 (주로 웹 기반) 애플리케이션
  - **알림 (alert)**: 사람이 읽을 수 있도록 작성된 통지(noification) 를 말하며, 주로 버그나 티켓 큐, 메일, 혹은 호출기 등으로 보내짐
  - **근본원인**: 소프트웨어 시스템의 결함이나 사람의 실수는 일단 고쳐지면 그 일이 다시는 발생하지 않을 것이라는 확신을 심어줌
  - **노드와 머신**: 물리적인 서버, 가상머신 혹은 컨테이너(container)에서 동작하는 커널의 단일 인스턴스를 의미하며 동의어로 사용됨
  - **푸시 (push)**: : 서비스가 실행하는 소프트웨어나 관련된 설정에 대한 모든 변경사항
- **네 가지 결정적인 지표**
  - **지연응답**: 요청이서비스에의해처리되기까지의시간빠르게 리턴된 에러보다는 느리게 리턴된 에러가 더 중요
  - **트래픽**: 시스템에 얼마나 많은 요청이 들어오는지를 측정초당 HTTP 요청의 개수로 측정
  - **에러**: 실패한 요청의 비율
  - **서비스 포화 상태**: 서비스가 얼마나 '포화 상태'로 동작 하는지를 의미

<br/>
</details>
<details>
<summary><b>CHAPTER 07. The Evolution of Automation at Google</b></summary>
<br>

[🔗 link](./chapter07)

<br/>

**TL;DR**

- **자동화의 가치 (자동화가 제공해주는 가치)**
  1. **Consistency**, 일관성: 정확히 정의된 업무 범위 + 정해진 절차 수행
  2. **A Platform**, 플랫폼: 올바르게 디자인되고 구현된 자동 시스템은 여러 이점을 가진 플랫폼 제공
     - 재발 방지: 자동화된 코드에서 수정된 버그는 한 번 수정되면 다시 발생하지 않음
  3. **Faster Repairs**, 더 신속한 수리: 시스템의 일반적인 장애를 해결하는 데 사용됩니다.
     - 평균 고장 후 수리 시간(MTTR) 절감: 장애에 대한 평균 고장 후 수리 시간(Mean Time to Repair, MTTR)의 절감 가능
  4. **Faster Action**, 더 신속한 조치: 사람이 기계만큼 빠르게 대응하는 것은 대체로 불가능
  5. **Time Saving**: 시간 절감
- **신뢰성은 근본적인 기능**
  - 운영자들이 제대로 대응하지 못하는 이유는 실전 경험의 부족
  - 그들이 생각하는 시스템의 동작이 실제 시스템의 동작과 일치하지 않기 때문
  - 오해는 수동 작업은 항상 수행이 가능할 것이라는 전제에서 발생
- **자동화는 시간을 절약하는 것 이상의 가치를 제공**
  - 단순히 자동화에 투입하는 시간과 그로 인해 절약되는 시간을 비교하는 것만으로는 판단하지 않았으면 함.

<br/>
</details>
<details>
<summary><b>CHAPTER 08. Release Engineering</b></summary>
<br>

[🔗 link](./chapter08)

<br/>

**TL;DR**

- 릴리즈 엔지니어링을 처음부터 도입하는 것이 중요

- 1️⃣ **릴리즈 엔지니어링**
  - 소프트웨어를 빌드하고 전달하는 과정을 간략하게 기술하는 분야.
  - 신뢰성 있는 서비스를 운영하려면 견고한 릴리즈 프로세스가 필요.
  - 모든 릴리즈 과정은 언제든지 동일하게 반복 실행될 수 있어야 함.
- 2️⃣ **릴리즈 엔지니어링 - 철학**
  1. **Self-Service Model**: 자동 빌드 시스템과 배포 도구를 이용해 많은 프로젝트가 자동으로 빌드되고 배포됨
  2. **High Velocity**: 변경 사항을 자주, 그리고 빠르게 릴리즈
  3. **Hermetic Builds**: 빌드 머신에 설치된 라이브러리나 다른 소프트웨어에 영향을 받지 않음.
  4. **Enforcement of Policies and Procedures**: 여러 단계의 보안 및 접근 제어 계층이 누가 어떤 작업을 수행할 수 있는지를 결정
- 3️⃣ **Rapid - 자동화 릴리즈 시스템**
  - 빌드와 테스트 대상, 배포 규칙, 관리용 정보(프로젝트 소유자) 등을 정의
  1. **Building**: Blaze (블레이즈) - C++, 자바, 파이썬, 고(Go), 자바스크립트 등 다양한 언어의 바이너리를 빌드하는 툴
  2. **Branching**: 모든 코드는 소스 코드 트리(메인라인)의 주 브랜치에 체크인됨.
  3. **Testing**: 변경된 코드가 제출될 때마다 코드에 대한 단위 테스트를 실행
  4. **Packaging**: Midas 패키지 관리자(Midas Package Manager, MPM)를 통해 프로덕션 환경의 머신에 배포
  5. **Deployment**: 시시포스 (Sisyphus) - **범용의 롤아웃(rollout) 자동화 프레임워크

<br/>
</details>
<details>
<summary><b>CHAPTER 09. Simplicity</b></summary>
<br>

[🔗 link](./chapter09)

<br/>

**TL;DR**

- 소프트웨어 시스템은 동적이고 불안정하며, 신속함과 안정성의 균형 유지가 핵심 과제임.
- **시스템 안정성 vs. 신속함**: 때로는 빠른 개발을 위해 안정성을 희생할 필요가 있으며, SRE는 신뢰성과 신속성을 동시에 높이는 절차와 도구를 개발함.
- **지루함의 미덕**: 소스코드는 복잡하지 않고 단조로울수록 바람직하며, 근본적 복잡성과 돌발적 복잡성을 구별하는 것이 중요함.
- **최소한의 API**: API는 작고 간결할수록 좋으며, 필요 없는 요소를 걷어내는 것이 이상적인 간결성을 만듦.
- **모듈화**: 독립적 변경이 가능해야 지속 가능한 시스템 구축이 가능함.
- 결론적으로, **간결함은 소프트웨어 신뢰성의 전제 조건**이며, 각 단계에서 단순화를 추구해야 함.
- 진정한 엔지니어링은 환경을 혼란스럽지 않게 유지하면서 혁신에 집중하는 것임.

<br/>
</details>

<details>
<summary><b>CHAPTER 10. Practical Alerting from Time-Series Data</b></summary>
<br>

[🔗 link](./chapter10)

<br/>

**TL;DR**

- **Borgmon**
  - 구글에서 개발한 시계열 모니터링 도구
  - 시스템 장애 탐지를 위해 스크립트를 실행하는 대신 표준화된 데이터 포맷 (Common Data Exposition Format) 사용.
  - **데이터 수집**
      - `/varz` URL을 각 대상마다 호출 → 결과 디코드 → 결과 값 메모리에 저장.
      - 메모리 내의 상태는 정기적으로 외부 시스템 - 시계열 데이터베이스 (Time-Series Database, TSDB) - 에 보관.
      - 오래된 데이터를 TSDB에 쿼리
      - 수집한 데이터는 차트 렌더링과 알림 생성에 사용되며, 대량 데이터 수집을 위해 지표 형식을 표준화.
  - 낮은 오버헤드로 대량 데이터 수집 가능.
  - 화이트 박스 모니터링 (white-box monitoring)
  - **유지 보수**: 광범위한 단위 테스트 및 회귀 테스트를 지원
- **Time window**: 연속된 데이터가 아니라 시계열로 분리된 데이터들을 다룰 때 조회 기간을 정해둠.
- **Alertmanager** (알림 매니저): 보그몬은 중앙 집중식으로 운영되는 알림 매니저에 연결됨
- **Borgmon Cluster**: 좀 더 복잡한 보그몬 클러스터에서는 "데이터센터 보그몬" 을 두어 수집 전용 계층으로 사용
- **Prober**: 프로버. 프로토콜의 응답 페이로드의 유효성 검사
- **Label**: 레이블. 보그몬에서 시계열 데이터를 그룹화하고 집계하는데 사용

<br/>
</details>

<details>
<summary><b>CHAPTER 11. Being On-Call</b></summary>
<br>

[🔗 link](./chapter11)

<br/>

**TL;DR**
- 비상 대기 중인 엔지니어는 프로덕션 환경에서 필요한 운영 작업을 사전 약속된 장애 시 대응 시간 내에 수행해야 함.
- **사전 약속된 장애 시 대응 시간**
    - 사용자에게 노출되거나, 시간이 중요한 서비스의 경우: 약 `5분`
    - 시간에 덜 민감한 서비스의 경우: 약 `30분`
- 사용자에게 노출되는 서비스의 경우 분기별로 `99.99%`의 가용성을 확보해야 함 → 분기 별 약 '13분'의 다운타임만 허용.
- SRE 팀은 **비상 대기 업무의 '양'과 '품질'에 대한 상세한 제약**을 둠.
    - **비상 대기 업무의 양**: 엔지니어가 비상 대기 업무에 할애한 시간의 백분율로 계산.
    - **비상 대기 업무의 품질**: 비상 대기 기간 동안 발생한 장애 수로 계산.
- **목표하는 SRE 업무 비중**: `[50%]` 엔지니어링 + `[25%]` 비상 대기 + `[25%]` 운영 업무
- **품질의 균형**: 비상 대기업무는 매 12시간마다 교대하므로 하루 최대 2개의 장애 처리가 가능.
- **합리적인 의사 결정을 위한 자원**
    - 분명한 장애 전파 경로
    - 잘 정의된 장애 관리 프로세스
    - 비난 없는 포스트모텀 문화
- SRE 지원 시스템을 개발하는 팀은 대부분 24/7 비상 대기업무를 교대로 투입되며, 필요 시 장애를 타 팀에 전파 가능
- **운영 부하**
    - **알림**: 모니터링 설정 오류는 운영 부담 증가를 초래 → 알림/장애 비율이 1:1이 되도록 조정
    - **타 팀 협조**: SRE는 개발 팀에게 시스템이 SRE 팀 기준에 도달할 때까지 비상 대기에 집중하도록 요청할 수 있음


<br/>
</details>

<details>
<summary><b>CHAPTER 12. Effective Troubleshooting</b></summary>
<br>

[🔗 link](./chapter12)

<br/>

**TL;DR**

- **장애 대응의 목표**
  1. 장애의 영향을 최소화하고 빠르게 복구하는 것.
  2. 장애의 재발을 방지하기 위한 근본 원인을 파악하는 것.
- 특정 시스템을 위한 사후 분석을 지원하는 도구와 템플릿 활용하는 것이 좋음
- 조사를 체계적으로 진행할 수 있는 절차를 마련.

#### 📌 장애 대응 절차:
1. **Problem Report** (문제 보고)
2. **Triage** (문제의 우선순위 판단)
3. **Examine** (문제를 관찰하기)
   1. 모니터링 지표
   2. 로그
   3. 상태 외부 노출
   4. 요청/응답 확인
4. **Diagnose** (진단)
   1. Simplify and reduce
   2. Ask "what," "where," and "why"
   3. What touched it last
   4. Specific diagnoses

#### 📌 테스트 구상 시 주의 사항
- 상호 배타적 테스트
- 명확하고 우선순위가 높은 테스트 고려
- 혼란 요소 주의
- 긴급한 테스트의 부작용
- 명확한 증거를 확보가 어려운 테스트의 한계

#### 📌 Negative Results Are Magic
- 부정적인 결과의 가치
- 부정적인 결과도 결론이 됨
- 도구와 방법의 의미
- 부정적인 결과의 공개는 업계의 데이터 주도성을 촉진
- 자신의 결과를 공표

<br/>
</details>

<details>
<summary><b>CHAPTER 13. Emergency Response</b></summary>
<br>

[🔗 link](./chapter13)

<br/>

**TL;DR**

- **세 가지 타입의 위기**
  - **Test-Induced Emergency** 
    - 사전적 테스트 접근법
    - 실제 복잡한 의존 관계 시스템으로 테스트 계획을 잘짜야 함
  - **Change-Induced Emergency**
    - 변경으로 인한 장애
    - 변경된 설정이 예상치 못한 결과나 동작이 발생하지 않도록 많은 테스트를 수행
  - **Process-Induced Emergency**
    - 절차에 의한 장애
    - 신속한 일처리가 위기 대응의 요점이 아님

- **세 가지 장애 타입 대응에서 공통점으로 배운 것**
  - 문제 원인이 명확하지 않은 상황도 해결책 존재
  - 해결책 생각나지 않으면 다른 사람에게 도움 청해야 함
  - '신속하게' 팀 동료 참여하고 도움 요청하고 할 수 있는 모든 것 시도해야 함
- **경험에서 배우고 반복하지 않기**
  - ✔️ 장애 기록 남기기
    - 광범위하고 솔직하게 작성하되, 무엇보다 중요한 것은 화두 던져야 하는 점
  - ✔️ What if? - 테스트에서는 불가능할 정도로까지 크게 의문 갖기
    - 사실, 현실보다 나은 테스트 없음
  - ✔️ 사전 수행하는 테스트
    - 장애 발생하기 전까지는 시스템과 그 시스템 의존 다른 시스템, 그리고 사용자가 어떻게 반응할지 아무도 모름

<br/>
</details>
<details>
<summary><b>CHAPTER 14. Managing Incidents</b></summary>
<br>

[🔗 link](./chapter14)

<br/>

**TL;DR**

📌 **장애 관리**
- ✔️ **핵심**
  - 장애로 인한 피해 최소화
  - 최대한 빨리 평소의 비즈니스 운영 복구
- ✔️ **액션**
  - 장애 관리 전략 사전에 수립하고, 이 전략을 잘 운영하고, 이 전략을 자주 되풀이해서 수행할 수 있도록 하면,
  - 장애 시 복구 시간과 직원들이 긴급한 문제 해결하는 데 받는 스트레스를 확실히 줄일 수 있음

- ✔️ **모범 사례**
  - 우선순위: 우선 출혈 막고 서비스 되살린 후 근본 원인 대한 증거 찾자.
  - 사전 준비: 장애 조치에 참여한 사람들의 자문받아 장애 관리 절차 미리 개발하고 문서화해두자.
  - 신뢰: 장애 조치에 참여 중인 모든 사람들에게 충분한 자율권 보장하자.
  - 감정 조절: 장애 조치하는 동안 스스로 감정적 상태 주의하자. 너무 부담 되면 다른 이에게 도움 청하자.
  - 대체 방안에 대한 모색: 주기적으로 현재 선택할 수 있는 방법 대해 다시 생각하고 이 방법이 여전히 유효한지, 아니면 다른 방법 찾아야 하는지 판단하자.
  - 실습: 이 과정을 정기적으로 수행해서 자연스럽게 활용할 수 있는 수준으로 만들자.
  - 개선: 그리고 계속해서 개선하자. 모든 팀 구성원들이 모든 역할에 익숙해질 수 있도록 독려하자.

<br/>
</details>

<details>
<summary><b>CHAPTER 15. Postmortem Culture: Learning from Failure</b></summary>
<br>

[🔗 link](./chapter15)

<br/>

**TL;DR**

- **포스트모텀**
  - : 장애의 발생 기록과 그 영향, 장애를 완화하거나 해결하기 위해 수행한 작업, 장애의 근본 원인, 그리고 향후 재발 방지를 위한 후속 조치 등이 기록된 문서
- **불행의 바퀴 (wheel of misfortune)**
  - : 이전의 포스트모텀 중 하나를 선정해서 엔지니어들이 그 안에 기록된 대로 역할을 수행해 보는 것. 
  - 새로 입사한 SRE들은 종종 불행의 바퀴 연습을 수행.
- **비난이 아닌 생산적인 포스트모텀 문서를 작성하는 방법**
  - 개인 · 팀의 실수나 부적절한 조치가 아닌, 장애를 유발한 원인을 판단하는 데 집중해야 함.
  - 참여자의 모든 행동 의도는 문제 해결임을 가정.
    - 당시 각자가 가진 모든 정보를 토대로 올바른 조치를 취한 것을 가정하고 작성해야함.
  - 누군가를 비난하지 않는 포스트모텀 문서를 작성하는 것은 어러움.
  - 장애를 유발시킨 모든 행위를 중심으로 명시.

<br/>
</details>

<details>
<summary><b>CHAPTER 16. Tracking Outages</b></summary>
<br>

[🔗 link](./chapter16)

<br/>

**TL;DR**

- **Outalator**
  - 서비스 중단 현상 추적 도구.
  - 모니터링 시스템이 발송하는 모든 알림을 수동으로 수신, 또 데이터를 해석, 그룹화 및 분석하기 위한 시스템
  - ✔️ **Queue**
    - 여러 큐에 보관된 알림을 시간별로 한 번에 확인할 수 있음
  - ✔️ **Tagging**
    - 모든 알림이 하나의 장애를 의미하지 않기 때문에, 알림 메타데이터 관리를 위해 태깅(tagging) 지원.
  - ✔️ **Analysis**
    - 기본적인 분석 계층은 보고서를 위한 산술, 통계, 집계 기능 포함.
- **Escalator**
  - 비상 대기 엔지니어에게 전달된 이메일 복사본 수신 도구로 기획된 시스템.
  - 구글에서는 SRE를 위한 모든 알림을 사람이 수신했는지 여부를 추적하는 중앙 응답 시스템을 공유하는데,
  - 설정된 시간이 지나도 아무도 수신을 확인하지 않으면 시스템은 다음 단계로 알림을 격상함.

<br/>
</details>

<details>
<summary><b>CHAPTER 17. Testing for Reliability</b></summary>
<br>

[🔗 link](./chapter17)

<br/>

**TLDR**

- 📌 **Testing**
  - SRE 엔지니어의 핵심 책임 중 하나는 시스템의 신뢰도를 정량화하는 것.
  - SRE 엔지니어는 시스템의 신뢰도를 정량화하고 유지하기 위해 다양한 테스트 종류(단위, 통합, 시스템, 프로덕션 등)를 수행해야 함. 
  - 테스트 환경을 구축, 대규모 환경에서 자동화 도구를 사용해 테스트를 관리, 재해 복구와 테스트 실패를 대비 등. 
  - **신뢰성 측정**
    - **과거의 신뢰성**: 모니터링 기록 시스템이 제공하는 분석 데이터를 통해 확인.
    - **미래의 신뢰성**: 예측 데이터를 정량화하여 확보.
  - **테스트의 중요성**
    - 변경 사항 발생 시 동일한 결과를 기대할 수 있음.
    - 테스트로 인한 소프트웨어나 서버의 변경이 없어야 함.
    - 모든 변경 사항에 대해 불확실성을 명확히 설명할 수 있어야 함.

- 📌 **Testing Type**
  - **Traditional Tests**
    - **단위 테스트**: 함수나 모듈이 정확히 동작하는지 확인.
    - **통합 테스트**: 의존성 주입 도구를 사용해 복잡한 의존 객체를 테스트.
    - **시스템 테스트**: 종단 간 기능을 테스트.
      - **스모크 테스트**: 중요한 동작을 간단하게 테스트.
      - **성능 테스트**: 시스템 성능 확인.
      - **회귀 테스트**: 기존 버그를 다시 확인.
  - **Production Tests**
    - **설정 테스트**: 설정 파일이 실제 프로덕션과 일치하는지 확인.
    - **스트레스 테스트**: 시스템의 한계를 검증.
    - **카나리 테스트**: 일부 서버에만 새로운 버전 적용 후 안정성 확인.


- 📌 **테스트 환경 구축**
  - 강력한 테스트 문화를 수립하고, 보고된 모든 버그를 테스트 케이스로 문서화.
  - Bazel 같은 도구로 소스 파일 변경에 따른 재빌드 최소화.
  - **대규모 환경에서의 테스트**
    - 대규모 환경에서는 여러 버전 간 테스트와 병합 필요.
    - 자동화 도구 사용 시 도구 간 상호작용 고려.
  - **재해 테스트**
    - 오프라인 및 온라인 복구 도구 사용.
    - 체크포인트와 무결성 도구를 통한 재시작 절차 지원.
  - **프로덕션 환경 테스트**
    - 프로덕션과 릴리즈 환경의 일치를 확보하기 위해 프로브 테스트와 자동화된 업데이트 수행.

- 📌 **테스트 실패 관리**
  - 신뢰성 관리와 릴리즈 주기 고려.
  - 테스트 커버리지 확보를 통해 사용자 애플리케이션의 신뢰성 유지.

</details>

<details>
<summary><b>CHAPTER 18. Software Engineering in SRE</b></summary>
<br>

[🔗 link](./chapter18)

<br/>

**TLDR**

- "팀의 규모는 서비스의 성장률과 직접적으로 비례해서는 안 된다."
- 📌 **성장하는 서비스에도 SRE 조직의 규모를 선형적으로 유지할 수 있는 요소**
  - 지속적인 자동화 작업와 효율적인 도구 개발.
  - 운영 절차 개선.
  - 일상적인 운영 업무의 비효율성을 새로운 시각.

- 📌 **수용량 계획은 끝나지 않는 작업 **
  - **Traditional Capacity Planning**
    1. 수요 예측 수집.  ← 전통적인 수용량 계획에서는 수요 예측 수집이 우선
    2. 빌드 및 할당 계획 수립.
    3. 리뷰 및 계획 승인.
    4. 배포 및 자원 설정.

  - **본질적으로 불안정**
    - 계획은 지속적으로 수정될 수밖에 없음.
  - **노동집약적이며 모호함**
    - **상자 채우기 문제(bin packing problem)**는 인간이 직접 계산하기 매우 어려운 NP-hard 문제에 해당.

- 📌 **의도 기반 수용량 계획(Intent-Based Capacity Planning)**
  - : 서비스 의존성과 수요를 프로그래밍적으로 인코딩하여, 클러스터와 서비스의 자원 할당 계획을 자동으로 생성하는 방식.

  - **의도 (Intent)**: 서비스 담당자가 해당 서비스를 운영하고자 하는 목적과 요구사항을 의미.
  - 현실적인 자원 수요를 바탕으로 수용량 계획 의도를 이끌어내기 위해 여러 단계의 추상화가 필요.

  - **의도 기반 수용량 계획을 위한 필수 정보**
    1. **Dependencies**: 의존성은 서비스의 위치 결정에 중요한 영향을 미침. 
    2. **Performance metrics**: 한 서비스의 수요는 다른 서비스의 수요에 영향을 미침.
    3. **Prioritization**: 자원 제약으로 인해 필연적으로 트레이드 오프와 어려운 결정을 내려야 하는 상황이 발생함.

- 📌 **소프트웨어 도입을 유도하기 위해선**:
  - **적절한 사용자층 정의**
  - **고객 서비스**: 제품을 조기에 사용하고자 하는 고객들이 적절히 활용할 수 있도록 지원을 아끼지 말아야 함
  - **적절한 수준의 디자인**
  - **팀의 원동력**: 폭넓은 지식과 경험을 가진 엔지니어와 다양한 기술을 빠르게 익힐 수 있는 엔지니어로 구성된 **시드 팀(sed 팀)** 을 만드는 것이 효과적

- 📌 SRE 조직에 소프트웨어 개발 모델을 도입을 위해:
  - 명확한 메시지로 소통하라
  - 조직의 역량을 평가하라
  - 출시하고 반복하라
  - 자신의 표준을 낮추지마라

</details>

<details>
<summary><b>CHAPTER 19. Load Balancing at the Frontend</b></summary>
<br>

[🔗 link](./chapter19)

<br/>

**TLDR**

- **📌 트래픽 분산 '최적화'의 의미**
  - 문제 해결을 위한 계층 레벨 (전역적 혹은 지역적)
  - 문제 해결을 위한 기술 수준 (하드웨어 혹은 소프트웨어)
  - 처리할 트래픽의 특성

- **📌 DNS Recursive Server**
  - : 사용자와 DNS 서버 사이의 질의를 대신 처리하고, 캐시 계층을 지원.
  - **주요 기능**:
    - IP 주소의 재귀적 해석
    - 비결정적 응답 경로
    - 추가 캐시 지원
  - **문제점**
    1. 특정 사용자 요청에 대한 최적의 IP 주소를 찾는 것
    2. 감당해야하는 사용자의 수
    3. 캐싱: 영향도 예측의 어려움
  - **구글의 해결법**
    - 트래픽 분석 및 DNS resolver 관리: 트래픽 변화를 분석하고, DNS resolver 목록 및 사용자 기반 규모를 지속적으로 업데이트하여 잠재적 영향을 추적.
      - 추적 중인 각 resolver 뒤에 있는 사용자들의 지리적 분포를 추정.
      - 해당 사용자들을 최적의 위치로 안내할 가능성을 높임.
    - **문제점**:
      - 지리적 분산의 문제: 사용자들이 넓게 분산된 경우, 최적의 위치와 경험 제공 중 하나를 선택해야 하는 딜레마 발생.

- 📌 **DNS 로드밸런싱의 한계**
  - **장점**: 연결 시작 전에 로드밸런싱을 수행할 수 있는 간단하고 효과적인 방법.
  - **단점**: RFC1035에 따른 512바이트 응답 크기 제한으로 인해 모든 서버 주소를 포함할 수 없음.
  - **해결방안**: DNS 로드밸런싱을 가상 IP 주소를 활용하는 방식으로 고도화해야 함 → Virtual IP Addresses

- 📌 **Virtual IP Addresses, VIPs**
  - : 가상 IP 주소. 일반 IP 주소처럼 보이지만, VIP는 특정 네트워크 인터페이스에 할당되지 않고 여러 장치에 의해 공유됨

- 📌 **네트워크 로드밸런서**
  - VIP 구현에서 가장 중요한 부분은 네트워크 로드밸런서.
  - **구현 방법**: 패킷의 일부를 이용해 연결 ID 생성 후 백엔드 선택

- 💥 **문제 1**: 백엔드 머신 장애나 제거된다면?
- ✅ **해결법**: Consistent Hashing 사용

- 💥 **문제 2**: Consistent Hashing - 추적 테이블 관리의 어려움
- ✅ **해결법**: DSR 구현: 데이터링크 계층 정보 조작 (OSI 네트워크 모델의 두번째 계층)

- 💥 **문제 3**: 두번째 계층을 사용하는 것은 대용량 시스템에 배포할 때 심각한 단점이 됨
- ✅ **해결법**: 구글의 해결책 - 패킷 캡슐화 (Packet Encapsulation)

</details>

<details>
<summary><b>Chapter 20. Load Balancing in the Datacenter</b></summary>
<br>

[🔗 link](./chapter20)

<br/>

**TLDR**

**📌 Subset Selection Algorithm**

1. Random Subsetting. 랜덤 서브셋
   - 각 클라이언트가 백엔드의 목록을 임의로 섞은 후, 그 중 접근이 가능하고 양호한 상태의 벡앤드를 선택해서 서브셋을 구축
2. Deterministic Subsetting. 결정적 서브셋
   - 랜덤 서브셋의 제한을 해결.
   - 매 라운드에서 각 백엔드는 정확히 하나의 클라이언트에 할당됨

**중요한 점:**
- 백엔드의 목록은 반드시 섞여야 함
  - 클라이언트가 할당된 연속적인 백엔드 스크의 그룹에 현재 사용 가능한 백엔드가 존재하지 않을 수 있음
- 각 라운드는 목록을 혼합할 때 각기 다른 시드값을 사용해야 함
  - 백엔드가 실패했을 때 해당 백엔드의 부하는 서브셋에 남아있는 백엔드 중 하나가 부담해야 함

**📌 Load Balancing Policies**
1. Simple Round Robin
   - 가장 보편적인 방법이면서 가장 간단한 방식.
   - 자신의 서브셋에 해당하는 각 백엔드 태스크에 요청을 보내는 방법.
2. Least-Loaded Round Robin
   - 각 클라이언트가 서브셋 내의 각 백엔드 태스크와 연결된 활성화된 요청의 개수를 추적하고, 가장 적은 수의 활성화된 요청을 처리하고 있는 태스크들만을 대상으로 라운드 로빈을 수행하는 것
3. Weighted Round Robin
   - 각 클라이언트 태스크는 서브셋 내의 각 백엔드의 수용량 점수를 저장
   - 요청은 라운드 로빈 형식으로 분산되지만, 클라이언트는 백엔드에 분산된 요청의 비율에 따라 가중치를 계산

</details>
<details>
<summary><b>Chapter 21. Handling Overload</b></summary>
<br>

[🔗 link](./chapter21)

<br/>

**TLDR**

**📌 과부하 처리 전략**
- **경감된 응답 제공**: 과부하 시 최상의 결과 대신 간소화된 응답을 제공.
- 극심한 과부하 시 에러 등 적은 비용의 응답을 리턴 반환.

**📌 자원 수용량 모델링**
- 초당 쿼리 수 대신 **CPU, 메모리 등의 자원**을 직접 측정하여 모델링.

**📌 클라이언트 측 사용량 제한**
- 클라이언트가 자체적으로 요청을 제한하고 조절하여 서버 부하 감소.
- 중요도 기반 요청 처리
  - 요청의 중요도에 따라 과부하 시 요청을 거부하거나 재시도.
  - **중요도**: 네가지의 중요도 값이 있으며 이를 기반으로 거부 정책을 실행
  -  `CRITICAL_PLUS`, `CRITICAL`, `SHEDDABLE_PLUS`, `SHEDDABLE`
- 활용도 신호: 시스템 활용도에 기반하여 요청의 중요도에 따라 처리 거부.

**📌 과부하 오류 관리**
- 과부하 오류 발생 시 재시도 여부를 결정하여 시스템 안정성 유지.
- 연결 부하 관리 및 로드 밸런싱: 연결 부하를 모니터링하고, 효과적인 로드 밸런싱을 통해 부하 분산.
- 일괄 프록시 사용: 일괄 프록시를 사용하여 부하를 완화하고 요청을 중개.

</details>

<details>
<summary><b>Chapter 22. Addressing Cascading Failures</b></summary>
<br>

[🔗 link](./chapter22)

<br/>


</details>

---

<details>
<summary><b>APPENDIX A. Availability Table</b></summary>
<br>

[🔗 link](./appendixA)

</details>

<details>
<summary><b>APPENDIX B. A Collection of Best Practices for Production Services</b></summary>
<br>

[🔗 link](./appendixB)

</details>

<br/><br/>
