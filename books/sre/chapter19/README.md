# Chapter 19. Load Balancing at the Frontend

<i><small>프런트엔드의 로드밸런싱</small></i>

단일 실패점에 의존하는 방법은 사용하지 않음. 대용량 시스템을 다룰 때는 단일 실패점이 재앙이 될 수 있음

<br><hr><br>

## Power Isn’t the Answer

<i><small>힘으로 모든 걸 해결할 수 없음</small></i>

매우 강력한 머신과 절대 장애가 일어나지 않는 네트워크를 보유할 수는 있지만, 
네트워크 인프라스트럭처에는 물리적 제약이 존재

(ex. 속도 제약이 존재하는 네트워크 인프라)

특정 요청을 어느 데이터센터에서 얼마나 많은 서버들이 처리할 것인지를 결정하기 위해 트래픽 로드밸런싱(traffic load balancing)이 필요

이상적으로는 트래픽이 여러 네트워크 링크, 데이터센터, 그리고 머신들에 최적화되어 분산되어야 함

<br>

### 트래픽 분산 '최적화'의 의미
- 문제 해결을 위한 계층 레벨 (전역적 혹은 지역적)
- 문제 해결을 위한 기술 수준 (하드웨어 혹은 소프트웨어)
- 처리할 트래픽의 특성

#### 예시: 검색 요청과 비디오 업로드 요청

- 검색 요청: 중요한 변수는 지연 응답
- 비디오 업로드: 중요한 변수는 처리량 - 실패 없는 업로드 요청 및 감내할 수 있는 시간

##### 최적의 요청 분산
- **글로벌 수준:**
  - 검색 요청: 요청에 대한 지연 응답 시간을 최소화 → 라운드 트립 타임(round-trip time, RTT)을 측정하여 가장 가까운 데이터센터로 전송
  - 비디오 업로드 스트림: 가장 사용량이 적은 경로 ← 지연 응답 시간을 희생하더라도 처리량을 극대화
- **지역적 수준:**
  - 데이터센터 내에 배치된 모든 머신은 사용자들로부터 동일한 거리만큼 떨어져 있고, 동일한 네트워크에 연결되는 것으로 간주
  - 따라서, 최적의 부하 분산은 자원 활용의 최적화 및 부하가 어느 한 서버로 몰리는 현상을 방지하는 것에 주력

실제는 훨씬 더 복잡함

<br><hr><br>

## Load Balancing Using DNS

DNS를 이용한 로드밸런싱

클라이언트는 HTTP 요청을 보내기 전에 DNS를 이용해 IP 주소를 먼저 조회.

이 DNS 조회 과정에 DNS 로드밸런싱이 적용됨.

가장 간단한 방법은 DNS 응답에 여러 개의 `A` 또는 `AAAA` 레코드를 리턴하여 클라이언트가 임의의 IP 주소를 선택하게 하는 방법

<br>

#### ✔️ 문제 1: 클라이언트의 행동을 제어할 수 없음

레코드는 임의로 선택되며, 각 레코드에는 거의 동일한 양의 트래픽이 전달됨

이론적으로, SRV 레코드를 이용해서 각 레코드에 전달될 트래픽의 양과 레코드의 우선순위를 명시할 수 있지만, SRV 레코드는 HTTP에 적용되지 않음

<br>

#### ✔️ 문제 2: 클라이언트가 가장 가까운 주소를 결정할 수 없음

이 문제는 공인 네임서버의 애니캐스트(anycast) 주소를 사용하여 DNS 질의가 가장 가까운 주소로 전달되는 방식을 이용해서 해결할 수 있음

서버는 DNS 질의에 대한 응답을 리턴할 때, 가장 가까운 데이터센터로 라우트할 수 있는 주소로 전환할 수 있음

**더 나은 방법**
: 모든 네트워크의 물리적 위치를 지도로 구축하고, 해당 매핑을 기반으로 DNS 응답을 제공

그러나, 훨씬 복잡한 DNS 서버를 구현하고 유지하는 데 비용이 필요

<br>

### DNS Recursive Server

- 사용자가 공인 네임 서버에 직접 접근하는 경우는 거의 없음
- 대부분 재귀 DNS 서버가 사용자와 네임 서버 사이를 중재함
- 이 서버는 사용자와 서버 사이의 질의를 대신 처리하고, 캐시 계층을 지원함

**DNS Recursive Server** (이하, '재귀 해석기')는 트래픽 관리를 위한 세 가지 주요 기능을 제공:

- IP 주소의 재귀적 해석
- 비결정적 응답 경로
- 추가 캐시 지원

<br>

#### 재귀 해석기 문제점 1: 특정 사용자 요청에 대한 최적의 IP 주소를 찾는 것

IP 주소의 재귀적 해석은 심각한 제한 문제

- → 공인 네임서버가 확인한 IP가 사용자의 것이 아니라 재귀 해석기의 주소가 됨
- → 해석기와 공인 네임서버 사이에서만 가장 가까운 거리를 위한 응답 최적화가 이루어짐

이를 해결하려면,
재귀 해석기가 보낸 DNS 질의에 클라이언트의 서브넷 정보를 포함하도록 EDNS0 확장을 사용하는 방법이 있음

#### EDNS0

공인 네임서버가 해석기가 아닌 사용자에게 최적화된 응답을 리턴할 수 있음

공식적인 표준으로 채택되지 않았지만, 현재 가장 큰 DNS 해석기(OpenDNS나 Google 등)가 이미 지원 중

- [Client Subnet in DNS Queries](https://datatracker.ietf.org/doc/html/draft-vandergaast-edns-client-subnet)
- [EDNS0: Extension Mechanisms for DNS](https://en.wikipedia.org/wiki/Extension_Mechanisms_for_DNS)

<br>

#### 재귀 해석기 문제점 2. 감당해야하는 사용자의 수

예를 들어, 한 국가의 대형 ISP가 전체 네트워크를 위한 네임서버들을 각 도시별로 운영하지 않고 하나의 데이터센터에서 운영한다고 가정

ISP의 네임서버들은 모든 사용자들에게 더 나은 네트워크 경로가 있든 없든 무조건 데이터센터에 최적화된 IP 주소를 리턴

<br>

#### 재귀 해석기 문제점 3. 캐싱: 영향도 예측의 어려움

**재귀 해석기의 캐시와 예측의 어려움**

- DNS 응답은 캐시되며 TTL(time-to-live) 내에 사용자에게 전달됨.
- 하나의 응답이 특정 사용자에게만 전달될 수도, 수천 명의 사용자에게 전달될 수도 있어 영향 예측이 어려움.

**구글의 해결법**

- 트래픽 분석 및 DNS resolver 관리: 트래픽 변화를 분석하고, DNS resolver 목록 및 사용자 기반 규모를 지속적으로 업데이트하여 잠재적 영향을 추적.
- 추적 중인 각 resolver 뒤에 있는 사용자들의 지리적 분포를 추정. 해당 사용자들을 최적의 위치로 안내할 가능성을 높임.

→ 지리적 분산의 문제: 사용자들이 넓게 분산된 경우, 최적의 위치와 경험 제공 중 하나를 선택해야 하는 딜레마 발생.

**DNS 로드밸런싱에서 최적의 위치란?**

- 일반적으로 사용자와 가장 가까운 위치가 최적.
- **조건**: 선택된 데이터센터가 충분한 수용력과 네트워크 연결성을 갖춰야 하며, 전력/네트워크 문제가 없는지 확인 필요.
- 글로벌 제어 시스템: 트래픽, 수용력, 인프라 상태를 추적하는 시스템을 공인 DNS 서버와 통합하여 최적화.

**캐시와 TTL의 영향**

- 캐시 갱신이 어렵다면 TTL을 낮게 설정해 변경 전파 속도의 하한선을 설정.
- 로드밸런싱 결정에서 캐시 특성 고려 필요.

**DNS 로드밸런싱의 한계**

- 장점: 연결 시작 전에 로드밸런싱을 수행할 수 있는 간단하고 효과적인 방법.
- 단점:
   - RFC1035에 따른 512바이트 응답 크기 제한으로 인해 모든 서버 주소를 포함할 수 없음.
   - 단순한 DNS 로드밸런싱은 프런트엔드 로드밸런싱 문제를 해결하기에 충분하지 않음.

**해결 방안**
- DNS 로드밸런싱을 가상 IP 주소를 활용하는 방식으로 고도화해야 함.

<br><hr><br>

## Load Balancing at the Virtual IP Address

사용자의 입장에서, VIP는 일반 IP 주소처럼 보임.

하지만 가상 IP 주소 (Virtual IP Addresses, VIPs)는 특정 네트워크 인터페이스에 할당되지 않고 여러 장치에 의해 공유됨

### 네트워크 로드밸런서

VIP 구현에서 가장 중요한 부분은 네트워크 로드밸런서.

로드밸런서는 패킷을 수신하고 이를 VIP 백엔드의 머신 중 하나에 전달하고, 이후 해당 백엔드 머신이 요청에 대한 추가 작업을 수행.


#### 어느 머신이 요청을 수신할 것인지를 결정하는 방법

##### 1. 부하가 가장 적은 머신 선택

가장 여유 있는 머신에게 요청이 전달되므로, 이론적으로 최상의 사용자 경험을 제공

문제점: 상태가 있는 (stateful) 프로토콜 사용 시 제한

해결법: 모든 네트워크 연결을 추적해서 패킷을 수신한 특정 백엔드를 확인

대안: 패킷의 일부를 이용해 연결 ID 생성 후 백엔드 선택

**예시:**

```
id(packet) mod N
```

- `id`: 패킷에서 연결 ID를 생성하는 함수
- `N`: 현재 보유 중인 백엔드 머신 개수

상태 저장 없이 모든 패킷이 항상 동일한 백엔드에 전달됨

<br>

#### 💥 문제 1: 백엔드 머신 장애나 제거된다면? 

백엔드 목록에서 머신이 제거될 때 `N`이 `N-1`로 감소, `id(packet) mod N`이 `id(packet) mod (N-1)`로 변경

-> 패킷이 갑자기 다른 백엔드에 전달될 수 있음

#### **✅ 해결법: Consistent Hashing 사용**

- 새로운 백엔드가 추가되거나 제거되더라도 안정적인 매핑을 제공
- 백엔드 풀 변화 시 기존 연결의 문제를 최소화
- 시스템 부하 증가 시 Consistent Hashing 기법 대체

<br><hr><br>

#### 💥 문제 2: Consistent Hashing - 추적 테이블 관리의 어려움

네트워크 로드밸런서가 정확하게 선택된 VIP 백엔드에 패킷을 전달하는 방법 중 하나는 네트워크 주소 해석 (Network Address Translation) 수행

→ 그러나 이 방법은 모든 연결에 대한 추적 테이블을 관리해야 하므로 완전한 대체 메커니즘을 사용하기 어려움

#### **✅ 해결법: DSR 구현**:
- 데이터링크 계층 정보 조작 (OSI 네트워크 모델의 두번째 계층)
- 로드밸런서가 전달된 패킷의 목적지 MAC 주소를 변경해 원래의 송신 및 수신 IP 주소를 유지

**장점**:
- 작은 크기의 요청만 로드밸런서를 통과하므로, 작은 크기의 요청이 많을 때 효과적

**문제점**:
- 두번째 계층을 사용하는 것은 대용량 시스템에 배포할 때 심각한 단점이 됨
   1. 모든 머신이 동일 브로드캐스트 도메인에 있어야 함
   2. 단일 브로드캐스트 도메인 네트워크에서만 사용 가능
      - but, 연결성이 네트워크에 의해 지원되고 머신의 수가 급격히 증가하지 않는다면 큰 문제가 되지는 않을 것
      - but, 구글은 이미 덩치가 너무 큼

<br>

### 구글의 VIP 로드 밸런싱 해결책: 패킷 캡슐화 (Packet Encapsulation)

- 네트워크 로드밸런서는 전달된 패킷을 GRE(Generic Routing Encapsulation)와 함께 다른 IP 패킷에 포함
- 백엔드에서는 패킷을 수신해 외부 IP+GRE 계층을 제거하고 내부 IP 패킷을 네트워크 인터페이스에 직접 전달된 것처럼 처리

**패킷 캡슐화의 장점**:
- 네트워크 로드밸런서와 백엔드가 같은 브로드캐스트 도메인에 있을 필요가 없으며, 라우터가 있다면 다른 대륙에서도 사용 가능
- 네트워크 설계와 개선에 필요한 유연성 제공

**단점**:
- 패킷 크기가 커짐
   - 오버헤드 발생 (IPv4+GRE의 경우 24바이트) → MTU(Maximum Transmission Unit) 크기 및 단편화 문제 발생 가능

**데이터센터에서 패킷 단편화 문제**:
- 데이터센터 내에서 더 큰 MTU로 해결 가능 → 큰 PDU(Protocol Data Unit)를 지원하는 네트워크 필요

로드밸런싱은 겉보기에 쉬워 보이나, 프런트엔드 로드밸런싱과 데이터센터 패킷 처리 양측면에서 어려움이 존재

