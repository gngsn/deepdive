# 분석 및 AI를 위한 데이터 기반: 데이터에서 대규모 성과로

어떻게 대규모의 데이터를 AI에게 학습 시켜 활용할까?

SageMaker -> SageMaker AI 리브랜딩
- Data & AI 거버넌스 <= 데이터를 포괄하는 개념으로 업그레이드
- Lakehouse: Unified Studio 에 통합되어 한 곳에서 관리 가능
- IceBerg 테이블과 완벽히 호환됨

ML을 만든다고 했을 때, 이탈률 기바에 대한 집계나 그래츠 생성

AWS Q Developer
소프트웨어 개발으 위한 가장 강력한 생성형 AI 어시스텐트
AWS 콘솔보면 Q 아이콘 볼 수 있음


#### S3는 핵심 저장소로 채택되어옴
- S3 Tables: Data Lake를 구성할 때 사용되곤 함
- 오픈 테이블 포맷 > 새로운 표준 > 상호 운영성 (Data <-> Tools)

#### 조직에서 데이터를 쌓는 방법

1. S3 Data Lake 를 구성
2. 어느정도 데이터가 형식화되면 Redshift를 사용하기 시작
3. 다양한 써드파트 서비스ㅇ와 함께 (MySQL, Redis, Google Cloud, Salesforce ... ) 사용됨
4. 이렇게 되면 아키텍처가 굉장히 복잡해지고, ==> Redshift data warehouse
   -> 선호하는 아파치 아이스버그 호화 컴퓨팅 엔진에서 데이터를 읽고 쓰기

**Zero-ETL integrations**: 연합 쿼리 가능 + 수백 새의 AWS Glue 커넥터 제공


데이터 아키텍처는 한 번 정의되면 변경이 어려움.
SageMaker AI => 기존의 데이터 환경과 데이터 소스 지켜서 가져올 수 있음.


#### 정형 데이터 / 비정형 데이터

데이터를 AI 에 적합한 형태로 만드는 게 중요해짐

- 데이터 소스
    - 데이터 준비 및 보강
    - AI 하면서 더 중요해짐. 특히 RAGs 사용하면서 더더 중요
    - 데이터 준비 보강 -> 메타데이터 (탐색 / 공유 / 이해 / 접근 / 이행 / 모니터링)

=> SageMake Catalog 를 통해 실현할 수 있음

---

#### 각 직군 별 어려움

- **데이터 엔지니어**
    - 데이터 파이프라인 구축
    - 팀원이 빠르게 데이터를 활용하게 만들고 싶음
- **데이터 과학자**
    - 빠르게 프로덕션을 만들어 자신의 AI 모델의 결과를 보고 싶음
- **분석가**
    - 적절한 데이터에 빠르게 접근을 원함.
    - SQL 쿼리 작성에 부담을 느낌
- **앱 개발자**
    - 더 많은 AI 모델을 각 프로덕트에 적용시켜 고도화하고 싶음


데이터가 차별화 요소이다
모든 팀원이 빠른, 원할한 협업이 중요

#### Since Using SageMaker AI

- **데이터 엔지니어**
    - 주피터 노트북 / 쿼리 에디터 환경 => 한 곳에 통합 (하나의 UI에서 사용 가능)
- **데이터 과학자**
    - 분석가가 만든 테이블을 확인해서 프로젝트에 활용 (분석 모델에 활용)
    - 파이프라인 바로 생성해서 만들어 공유
- **분석가**
    - Amazon Q(생성형 AI)가 바로 옆 탭에 위치해서 질의하고 쿼리를 요청할 수 있음
    - (개인 의견) Structure Language인 SQL 짜는 건 좋은 아이디어. SQL 짜는 기능에 초점을 맞춘 AI라면 좋은 결과를 내줄거라 믿음
    - 소셜 지표(구매, 활동)를 구하고 싶을 때, 데이터를 새로운 테이블로 생성하여 SageMaker Catalog로 설명과 함께 팀원들에게 공유
- **앱 개발자**
    - 과학자가 생성한 새로운 모델을 검색/구독 가능
    - BedRock ID 를 활용 (?)
    - 가이라인 트레이닝 등 제작 가능

=> 실시간에 가까운 협업
(개인 의견) 실시간까진 아닌데 ... 한 곳에 모아서 통합된 환경에서 작업할 수 있다는 장점이 보임
(예외는 없을까?)  
